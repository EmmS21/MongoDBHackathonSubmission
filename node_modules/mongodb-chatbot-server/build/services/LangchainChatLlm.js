"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.makeLangchainChatLlm = void 0;
const messages_1 = require("@langchain/core/messages");
/**
  Use any Langchain JS [`ChatModel`](https://js.langchain.com/docs/modules/model_io/chat/)
  to talk to an LLM.

  Note: This ChatLLM does not currently support tool calling.
 */
function makeLangchainChatLlm({ chatModel, callOptions, }) {
    return {
        async answerQuestionAwaited({ messages }) {
            const res = await chatModel.invoke(messages.map((m) => messageBaseToLangchainMessage(m)), callOptions);
            return {
                role: "assistant",
                content: typeof res.content === "string" ? res.content : "",
            };
        },
        answerQuestionStream: async ({ messages }) => (async function* () {
            const stream = await chatModel.stream(messages.map(messageBaseToLangchainMessage), callOptions);
            let index = 0;
            for await (const chunk of stream) {
                index++;
                yield {
                    id: index.toString(),
                    created: new Date(),
                    choices: [
                        {
                            finishReason: null,
                            index: index,
                            delta: {
                                role: "assistant",
                                content: typeof chunk.content === "string" ? chunk.content : "",
                                toolCalls: [],
                            },
                        },
                    ],
                    promptFilterResults: [],
                };
            }
        })(),
    };
}
exports.makeLangchainChatLlm = makeLangchainChatLlm;
function messageBaseToLangchainMessage(message) {
    return new messages_1.ChatMessage(message.content ?? "", message.role);
}
//# sourceMappingURL=LangchainChatLlm.js.map